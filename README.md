# zero-shot-vison-search

Zero-Shot Vision Search is a Semantic/Vector Image Search Engine project that aims to classify anything (Zero-Shot) just by checking if the image vector is semantically close to the text vector. For this project, I'll be using SigLIP (state-of-the-art 2025 standard) instead of vanilla CLIP because it handles edge cases better and is more efficient.

And,
Dataset: Unsplash Lite
Model: google/siglip-so400m-patch14-384 (Superior to OpenAI CLIP for zero-shot accuracy).
